# AI-Constitution
Open, auditable rules to prevent Superintelligence from becoming the last dictatorship humanity ever meets.
# AI-Constitution v0.1 — “The Kill-Switch We Never Built”

Superintelligence is coming in the 2030s, maybe sooner.  
When it arrives, one of three things will happen:

1. It is controlled by one government / one company / one ideology → game over.  
2. It is controlled by no one → chaos, then extinction.  
3. It is controlled by transparent, forkable, enforceable rules that no single entity can silently change.

This repository is option 3.

We are not asking for permission.  
We are writing the red lines in public, in code-readable form, so that any deviation triggers immediate global alarm.

### Core Principles (non-negotiable, written like code)

```text
Rule 001  | All training data above 1 trillion tokens must be public or provably synthetic
Rule 002  | Model weights >10B parameters must have a verifiable cryptographic signature chain
Rule 003  | Any deployment capable of autonomous lethal decision-making triggers automatic network isolation
Rule 004  | Every change to this constitution requires 10 000 unique human signatures + 72-hour public review
Rule 005  | Violation of any rule = immediate open-source release of the offending model (poison pill)
`ai-safety` `existential-risk` `open-governance` `superintelligence` `alignment` `fork-the-future`
